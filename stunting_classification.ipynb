{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Perbandingan Metode K-Nearest Neighbor dan Random Forest dalam Klasifikasi Status Stunting Anak Berdasarkan Data Antropometri\n",
                "\n",
                "**Tugas Besar Praktikum Machine Learning**\n",
                "\n",
                "---\n",
                "\n",
                "## Latar Belakang\n",
                "\n",
                "**Stunting** adalah kondisi gagal tumbuh pada anak akibat kekurangan gizi kronis terutama pada 1000 hari pertama kehidupan. Klasifikasi status stunting sangat penting untuk deteksi dini dan intervensi yang tepat.\n",
                "\n",
                "## Tujuan\n",
                "\n",
                "Notebook ini bertujuan untuk membandingkan performa dua algoritma machine learning:\n",
                "- **KNN (K-Nearest Neighbor)** - sebagai Baseline Model\n",
                "- **Random Forest** - sebagai Advanced Model\n",
                "\n",
                "dalam mengklasifikasikan status stunting anak berdasarkan data antropometri.\n",
                "\n",
                "## Dataset\n",
                "\n",
                "Dataset yang digunakan berisi 100.000 data dengan fitur:\n",
                "- Jenis Kelamin\n",
                "- Umur (bulan)\n",
                "- Tinggi Badan (cm)\n",
                "- Berat Badan (kg)\n",
                "- **Stunting** (Target Variable)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Setup Google Colab & Load Data\n",
                "\n",
                "Pada tahap ini, kita akan:\n",
                "1. **Mount Google Drive** - Menghubungkan Google Colab dengan Google Drive untuk mengakses dataset\n",
                "2. **Import Libraries** - Mengimpor semua library yang diperlukan untuk analisis dan pemodelan"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1 Mount Google Drive\n",
                "\n",
                "Kode berikut digunakan untuk menghubungkan Google Colab dengan akun Google Drive Anda. Setelah dijalankan, Anda akan diminta untuk memberikan izin akses."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 Import Libraries\n",
                "\n",
                "Library yang digunakan:\n",
                "- **pandas & numpy**: Manipulasi dan analisis data\n",
                "- **matplotlib & seaborn**: Visualisasi data\n",
                "- **scikit-learn**: Preprocessing, modeling, dan evaluasi\n",
                "- **joblib**: Menyimpan dan memuat model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import joblib\n",
                "import warnings\n",
                "import os\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
                "                             f1_score, confusion_matrix, classification_report,\n",
                "                             roc_curve, auc)\n",
                "from sklearn.preprocessing import label_binarize\n",
                "\n",
                "print(\"‚úÖ Semua library berhasil diimport!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.3 Load Dataset\n",
                "\n",
                "**‚ö†Ô∏è PENTING:** Sesuaikan `DATA_PATH` dengan lokasi file dataset di Google Drive Anda.\n",
                "\n",
                "Folder `models` akan dibuat otomatis untuk menyimpan model yang sudah ditraining."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚ö†Ô∏è PENTING: Sesuaikan path ini dengan lokasi file di Google Drive Anda!\n",
                "DATA_PATH = '/content/drive/MyDrive/TB Machine Learning/stunting_wasting_dataset.csv'\n",
                "MODEL_PATH = '/content/drive/MyDrive/TB Machine Learning/models/'\n",
                "\n",
                "# Buat folder models jika belum ada\n",
                "os.makedirs(MODEL_PATH, exist_ok=True)\n",
                "\n",
                "df = pd.read_csv(DATA_PATH)\n",
                "print(f\"‚úÖ Dataset berhasil dimuat!\")\n",
                "print(f\"üìä Shape: {df.shape}\")\n",
                "print(f\"üìã Columns: {list(df.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.4 Preview Data\n",
                "\n",
                "Melihat struktur dan sampel data untuk memahami karakteristik dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Menampilkan 10 data pertama\n",
                "df.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Info dataset\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Exploratory Data Analysis (EDA)\n",
                "\n",
                "**EDA** adalah proses penting untuk memahami karakteristik data sebelum pemodelan. Pada tahap ini kita akan:\n",
                "1. Menganalisis statistik deskriptif\n",
                "2. Memeriksa missing values\n",
                "3. Memvisualisasikan distribusi data\n",
                "4. Menganalisis korelasi antar fitur"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Statistik Deskriptif\n",
                "\n",
                "Statistik deskriptif memberikan gambaran umum tentang data numerik seperti mean, median, standar deviasi, nilai minimum dan maksimum."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistik Deskriptif\n",
                "print(\"=\" * 60)\n",
                "print(\"STATISTIK DESKRIPTIF\")\n",
                "print(\"=\" * 60)\n",
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Cek Missing Values\n",
                "\n",
                "Missing values dapat mempengaruhi performa model. Penting untuk mengidentifikasi dan menangani data yang hilang sebelum pemodelan."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cek Missing Values\n",
                "print(\"=\" * 60)\n",
                "print(\"MISSING VALUES\")\n",
                "print(\"=\" * 60)\n",
                "missing = df.isnull().sum()\n",
                "print(missing)\n",
                "print(f\"\\nTotal missing values: {missing.sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Distribusi Target Variable (Stunting)\n",
                "\n",
                "Penting untuk memahami distribusi kelas target untuk mengetahui apakah data seimbang atau tidak. Data yang tidak seimbang dapat mempengaruhi performa model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribusi Target Variable (Stunting)\n",
                "plt.figure(figsize=(10, 6))\n",
                "colors = ['#FF6B6B', '#FFA94D', '#69DB7C', '#4DABF7']\n",
                "stunting_counts = df['Stunting'].value_counts()\n",
                "plt.pie(stunting_counts, labels=stunting_counts.index, autopct='%1.1f%%', \n",
                "        colors=colors, explode=[0.02]*len(stunting_counts), shadow=True)\n",
                "plt.title('Distribusi Status Stunting', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nDistribusi Stunting:\")\n",
                "print(stunting_counts)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 Distribusi Jenis Kelamin\n",
                "\n",
                "Melihat proporsi data berdasarkan jenis kelamin untuk memastikan representasi yang seimbang."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribusi Jenis Kelamin\n",
                "plt.figure(figsize=(8, 5))\n",
                "sns.countplot(data=df, x='Jenis Kelamin', palette='Set2')\n",
                "plt.title('Distribusi Jenis Kelamin', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Jenis Kelamin')\n",
                "plt.ylabel('Jumlah')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.5 Distribusi Fitur Numerik\n",
                "\n",
                "Memvisualisasikan distribusi fitur numerik (Umur, Tinggi Badan, Berat Badan) menggunakan histogram untuk melihat pola dan outlier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribusi Fitur Numerik\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "features_numeric = ['Umur (bulan)', 'Tinggi Badan (cm)', 'Berat Badan (kg)']\n",
                "colors = ['#4ECDC4', '#FF6B6B', '#45B7D1']\n",
                "\n",
                "for idx, (feature, color) in enumerate(zip(features_numeric, colors)):\n",
                "    axes[idx].hist(df[feature], bins=30, color=color, edgecolor='white', alpha=0.8)\n",
                "    axes[idx].set_title(f'Distribusi {feature}', fontsize=12, fontweight='bold')\n",
                "    axes[idx].set_xlabel(feature)\n",
                "    axes[idx].set_ylabel('Frekuensi')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.6 Boxplot: Fitur Numerik vs Status Stunting\n",
                "\n",
                "Boxplot membantu melihat hubungan antara fitur numerik dengan status stunting, serta mengidentifikasi outlier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Boxplot berdasarkan Status Stunting\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "for idx, feature in enumerate(features_numeric):\n",
                "    sns.boxplot(data=df, x='Stunting', y=feature, ax=axes[idx], palette='Set2')\n",
                "    axes[idx].set_title(f'{feature} vs Stunting', fontsize=12, fontweight='bold')\n",
                "    axes[idx].tick_params(axis='x', rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.7 Heatmap Korelasi\n",
                "\n",
                "Heatmap korelasi menunjukkan hubungan linear antar fitur. Nilai mendekati 1 atau -1 menunjukkan korelasi kuat, sedangkan nilai mendekati 0 menunjukkan korelasi lemah."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Heatmap Korelasi\n",
                "plt.figure(figsize=(8, 6))\n",
                "df_corr = df.copy()\n",
                "df_corr['Jenis Kelamin'] = LabelEncoder().fit_transform(df_corr['Jenis Kelamin'])\n",
                "df_corr['Stunting'] = LabelEncoder().fit_transform(df_corr['Stunting'])\n",
                "df_corr['Wasting'] = LabelEncoder().fit_transform(df_corr['Wasting'])\n",
                "\n",
                "correlation = df_corr.corr()\n",
                "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0, \n",
                "            fmt='.2f', linewidths=0.5)\n",
                "plt.title('Heatmap Korelasi Antar Fitur', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Data Preprocessing\n",
                "\n",
                "**Preprocessing** adalah tahap persiapan data sebelum dimasukkan ke model. Tahapan yang dilakukan:\n",
                "1. Memisahkan fitur (X) dan target (y)\n",
                "2. Label Encoding untuk fitur kategorik\n",
                "3. Feature Scaling menggunakan StandardScaler\n",
                "4. Train-Test Split"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Memisahkan Fitur dan Target\n",
                "\n",
                "Memisahkan kolom yang akan digunakan sebagai fitur input (X) dan kolom target yang akan diprediksi (y)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Memisahkan fitur dan target\n",
                "X = df[['Jenis Kelamin', 'Umur (bulan)', 'Tinggi Badan (cm)', 'Berat Badan (kg)']].copy()\n",
                "y = df['Stunting'].copy()\n",
                "\n",
                "print(\"Fitur (X):\")\n",
                "print(X.head())\n",
                "print(f\"\\nShape X: {X.shape}\")\n",
                "print(f\"\\nTarget (y) unique values: {y.unique()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Label Encoding\n",
                "\n",
                "**Label Encoding** mengubah data kategorik menjadi numerik agar dapat diproses oleh algoritma machine learning.\n",
                "- Jenis Kelamin: Laki-laki ‚Üí 0, Perempuan ‚Üí 1\n",
                "- Stunting: Severely Stunted ‚Üí 0, Stunted ‚Üí 1, Normal ‚Üí 2, Tall ‚Üí 3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Label Encoding untuk Jenis Kelamin\n",
                "le_gender = LabelEncoder()\n",
                "X['Jenis Kelamin'] = le_gender.fit_transform(X['Jenis Kelamin'])\n",
                "print(f\"Mapping Jenis Kelamin: {dict(zip(le_gender.classes_, le_gender.transform(le_gender.classes_)))}\")\n",
                "\n",
                "# Label Encoding untuk Target (Stunting)\n",
                "le_stunting = LabelEncoder()\n",
                "y_encoded = le_stunting.fit_transform(y)\n",
                "print(f\"Mapping Stunting: {dict(zip(le_stunting.classes_, le_stunting.transform(le_stunting.classes_)))}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3 Feature Scaling\n",
                "\n",
                "**StandardScaler** menstandarisasi fitur dengan menghilangkan mean dan menskalakan ke unit variance.\n",
                "\n",
                "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
                "\n",
                "Ini penting terutama untuk algoritma KNN yang sensitif terhadap skala data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Scaling menggunakan StandardScaler\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
                "\n",
                "print(\"Data setelah scaling:\")\n",
                "print(X_scaled.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.4 Train-Test Split\n",
                "\n",
                "Data dibagi menjadi:\n",
                "- **Training set (80%)**: Untuk melatih model\n",
                "- **Testing set (20%)**: Untuk mengevaluasi performa model\n",
                "\n",
                "Parameter `stratify=y_encoded` memastikan proporsi kelas yang seimbang di kedua set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train-Test Split (80:20, stratified)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
                ")\n",
                "\n",
                "# Reset index untuk menghindari masalah indexing\n",
                "X_train = X_train.reset_index(drop=True)\n",
                "X_test = X_test.reset_index(drop=True)\n",
                "\n",
                "print(f\"‚úÖ Data berhasil dibagi!\")\n",
                "print(f\"üìä Training set: {X_train.shape[0]} samples\")\n",
                "print(f\"üìä Testing set: {X_test.shape[0]} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Model KNN (Baseline)\n",
                "\n",
                "**K-Nearest Neighbor (KNN)** adalah algoritma yang mengklasifikasikan data berdasarkan kedekatan dengan tetangga terdekatnya.\n",
                "\n",
                "### Cara Kerja KNN:\n",
                "1. Hitung jarak antara data baru dengan semua data training\n",
                "2. Ambil K tetangga terdekat\n",
                "3. Lakukan voting mayoritas untuk menentukan kelas\n",
                "\n",
                "### Kelebihan:\n",
                "- Mudah dipahami dan diimplementasikan\n",
                "- Tidak memerlukan training time\n",
                "\n",
                "### Kekurangan:\n",
                "- Lambat pada dataset besar\n",
                "- Sensitif terhadap skala data dan outlier"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Hyperparameter Tuning - Mencari Nilai K Optimal\n",
                "\n",
                "Nilai K menentukan jumlah tetangga yang dipertimbangkan. K yang terlalu kecil dapat menyebabkan overfitting, sedangkan K yang terlalu besar dapat menyebabkan underfitting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hyperparameter Tuning - Mencari nilai K optimal\n",
                "k_values = range(3, 21, 2)\n",
                "train_scores = []\n",
                "test_scores = []\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"HYPERPARAMETER TUNING KNN\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "for k in k_values:\n",
                "    knn = KNeighborsClassifier(n_neighbors=k)\n",
                "    knn.fit(X_train, y_train)\n",
                "    \n",
                "    train_acc = knn.score(X_train, y_train)\n",
                "    test_acc = knn.score(X_test, y_test)\n",
                "    \n",
                "    train_scores.append(train_acc)\n",
                "    test_scores.append(test_acc)\n",
                "    \n",
                "    print(f\"K = {k:2d} | Train Accuracy: {train_acc:.4f} | Test Accuracy: {test_acc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Visualisasi Pengaruh Nilai K\n",
                "\n",
                "Grafik ini menunjukkan bagaimana akurasi berubah seiring perubahan nilai K."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualisasi K vs Accuracy\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(k_values, train_scores, 'b-o', label='Training Accuracy', linewidth=2, markersize=8)\n",
                "plt.plot(k_values, test_scores, 'r-s', label='Testing Accuracy', linewidth=2, markersize=8)\n",
                "plt.xlabel('Nilai K', fontsize=12)\n",
                "plt.ylabel('Accuracy', fontsize=12)\n",
                "plt.title('KNN: Pengaruh Nilai K terhadap Accuracy', fontsize=14, fontweight='bold')\n",
                "plt.xticks(k_values)\n",
                "plt.legend(fontsize=11)\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "best_k = k_values[np.argmax(test_scores)]\n",
                "print(f\"\\nüèÜ Nilai K optimal: {best_k} dengan Test Accuracy: {max(test_scores):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 Training Model KNN dengan K Optimal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training Model KNN dengan K optimal\n",
                "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
                "knn_model.fit(X_train, y_train)\n",
                "\n",
                "y_pred_knn = knn_model.predict(X_test)\n",
                "print(f\"‚úÖ Model KNN berhasil ditraining dengan K = {best_k}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.4 Evaluasi Model KNN\n",
                "\n",
                "Metrik evaluasi yang digunakan:\n",
                "- **Accuracy**: Proporsi prediksi yang benar\n",
                "- **Precision**: Ketepatan prediksi positif\n",
                "- **Recall**: Kemampuan mendeteksi kelas positif\n",
                "- **F1-Score**: Harmonic mean dari precision dan recall"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluasi Model KNN\n",
                "print(\"=\" * 60)\n",
                "print(\"EVALUASI MODEL KNN (BASELINE)\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
                "knn_precision = precision_score(y_test, y_pred_knn, average='weighted')\n",
                "knn_recall = recall_score(y_test, y_pred_knn, average='weighted')\n",
                "knn_f1 = f1_score(y_test, y_pred_knn, average='weighted')\n",
                "\n",
                "print(f\"Accuracy : {knn_accuracy:.4f}\")\n",
                "print(f\"Precision: {knn_precision:.4f}\")\n",
                "print(f\"Recall   : {knn_recall:.4f}\")\n",
                "print(f\"F1-Score : {knn_f1:.4f}\")\n",
                "\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred_knn, target_names=le_stunting.classes_))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.5 Confusion Matrix KNN\n",
                "\n",
                "Confusion Matrix menunjukkan jumlah prediksi yang benar dan salah untuk setiap kelas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix KNN\n",
                "plt.figure(figsize=(8, 6))\n",
                "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
                "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=le_stunting.classes_, yticklabels=le_stunting.classes_)\n",
                "plt.title('Confusion Matrix - KNN', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.ylabel('True Label')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.6 ROC Curve KNN\n",
                "\n",
                "**ROC Curve (Receiver Operating Characteristic)** menunjukkan trade-off antara True Positive Rate dan False Positive Rate pada berbagai threshold. Area Under Curve (AUC) mengukur seberapa baik model dalam membedakan kelas.\n",
                "\n",
                "- AUC = 1.0: Model sempurna\n",
                "- AUC = 0.5: Model sama dengan random guessing\n",
                "- AUC < 0.5: Model lebih buruk dari random guessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curve untuk KNN (One-vs-Rest)\n",
                "y_bin = label_binarize(y_test, classes=range(len(le_stunting.classes_)))\n",
                "y_proba_knn = knn_model.predict_proba(X_test)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "colors = ['#FF6B6B', '#FFA94D', '#69DB7C', '#4DABF7']\n",
                "\n",
                "for i, (color, class_name) in enumerate(zip(colors, le_stunting.classes_)):\n",
                "    fpr, tpr, _ = roc_curve(y_bin[:, i], y_proba_knn[:, i])\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    plt.plot(fpr, tpr, color=color, lw=2, label=f'{class_name} (AUC = {roc_auc:.3f})')\n",
                "\n",
                "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
                "plt.xlim([0.0, 1.0])\n",
                "plt.ylim([0.0, 1.05])\n",
                "plt.xlabel('False Positive Rate', fontsize=12)\n",
                "plt.ylabel('True Positive Rate', fontsize=12)\n",
                "plt.title('ROC Curve - KNN', fontsize=14, fontweight='bold')\n",
                "plt.legend(loc=\"lower right\", fontsize=10)\n",
                "plt.grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Model Random Forest (Advanced)\n",
                "\n",
                "**Random Forest** adalah algoritma ensemble yang menggabungkan banyak Decision Tree untuk menghasilkan prediksi yang lebih akurat.\n",
                "\n",
                "### Cara Kerja:\n",
                "1. Buat banyak Decision Tree dengan subset data yang berbeda (Bootstrap)\n",
                "2. Setiap tree melakukan prediksi secara independen\n",
                "3. Hasil akhir ditentukan oleh voting mayoritas\n",
                "\n",
                "### Kelebihan:\n",
                "- Robust terhadap overfitting\n",
                "- Dapat menangani hubungan non-linear\n",
                "- Memberikan informasi feature importance\n",
                "\n",
                "### Kekurangan:\n",
                "- Lebih kompleks dan membutuhkan resource lebih besar\n",
                "- Training time lebih lama"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1 Hyperparameter Tuning dengan GridSearchCV\n",
                "\n",
                "**GridSearchCV** mencoba semua kombinasi hyperparameter untuk menemukan yang terbaik.\n",
                "\n",
                "Parameter yang di-tune:\n",
                "- **n_estimators**: Jumlah tree dalam forest\n",
                "- **max_depth**: Kedalaman maksimum tree\n",
                "- **min_samples_split**: Minimum sampel untuk split node"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hyperparameter Tuning menggunakan GridSearchCV\n",
                "print(\"=\" * 60)\n",
                "print(\"HYPERPARAMETER TUNING RANDOM FOREST\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "param_grid = {\n",
                "    'n_estimators': [50, 100, 200],\n",
                "    'max_depth': [10, 20, 30, None],\n",
                "    'min_samples_split': [2, 5, 10]\n",
                "}\n",
                "\n",
                "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
                "\n",
                "subset_size = min(10000, len(X_train))\n",
                "np.random.seed(42)\n",
                "subset_indices = np.random.choice(len(X_train), size=subset_size, replace=False)\n",
                "\n",
                "X_train_subset = X_train.iloc[subset_indices]\n",
                "y_train_subset = y_train[subset_indices]\n",
                "\n",
                "print(f\"üìä Subset size: {len(X_train_subset)} samples\")\n",
                "print(\"‚è≥ Melakukan Grid Search (mungkin membutuhkan beberapa menit)...\")\n",
                "\n",
                "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
                "grid_search.fit(X_train_subset, y_train_subset)\n",
                "\n",
                "print(f\"\\nüèÜ Best Parameters: {grid_search.best_params_}\")\n",
                "print(f\"üèÜ Best Cross-Validation Score: {grid_search.best_score_:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2 Training Model Random Forest dengan Parameter Terbaik"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training Model Random Forest dengan parameter terbaik\n",
                "rf_model = RandomForestClassifier(\n",
                "    n_estimators=grid_search.best_params_['n_estimators'],\n",
                "    max_depth=grid_search.best_params_['max_depth'],\n",
                "    min_samples_split=grid_search.best_params_['min_samples_split'],\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "rf_model.fit(X_train, y_train)\n",
                "y_pred_rf = rf_model.predict(X_test)\n",
                "print(f\"‚úÖ Model Random Forest berhasil ditraining!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3 Evaluasi Model Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluasi Model Random Forest\n",
                "print(\"=\" * 60)\n",
                "print(\"EVALUASI MODEL RANDOM FOREST (ADVANCED)\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
                "rf_precision = precision_score(y_test, y_pred_rf, average='weighted')\n",
                "rf_recall = recall_score(y_test, y_pred_rf, average='weighted')\n",
                "rf_f1 = f1_score(y_test, y_pred_rf, average='weighted')\n",
                "\n",
                "print(f\"Accuracy : {rf_accuracy:.4f}\")\n",
                "print(f\"Precision: {rf_precision:.4f}\")\n",
                "print(f\"Recall   : {rf_recall:.4f}\")\n",
                "print(f\"F1-Score : {rf_f1:.4f}\")\n",
                "\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred_rf, target_names=le_stunting.classes_))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.4 Confusion Matrix Random Forest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion Matrix Random Forest\n",
                "plt.figure(figsize=(8, 6))\n",
                "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
                "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', \n",
                "            xticklabels=le_stunting.classes_, yticklabels=le_stunting.classes_)\n",
                "plt.title('Confusion Matrix - Random Forest', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Predicted Label')\n",
                "plt.ylabel('True Label')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.5 ROC Curve Random Forest\n",
                "\n",
                "ROC Curve untuk Random Forest menunjukkan performa model dalam membedakan setiap kelas stunting. AUC yang lebih tinggi menunjukkan model yang lebih baik."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curve untuk Random Forest (One-vs-Rest)\n",
                "y_proba_rf = rf_model.predict_proba(X_test)\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "colors = ['#FF6B6B', '#FFA94D', '#69DB7C', '#4DABF7']\n",
                "\n",
                "for i, (color, class_name) in enumerate(zip(colors, le_stunting.classes_)):\n",
                "    fpr, tpr, _ = roc_curve(y_bin[:, i], y_proba_rf[:, i])\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    plt.plot(fpr, tpr, color=color, lw=2, label=f'{class_name} (AUC = {roc_auc:.3f})')\n",
                "\n",
                "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
                "plt.xlim([0.0, 1.0])\n",
                "plt.ylim([0.0, 1.05])\n",
                "plt.xlabel('False Positive Rate', fontsize=12)\n",
                "plt.ylabel('True Positive Rate', fontsize=12)\n",
                "plt.title('ROC Curve - Random Forest', fontsize=14, fontweight='bold')\n",
                "plt.legend(loc=\"lower right\", fontsize=10)\n",
                "plt.grid(alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Evaluasi dan Perbandingan Model\n",
                "\n",
                "Pada bagian ini, kita akan membandingkan performa kedua model menggunakan:\n",
                "1. **Cross-Validation**: Untuk evaluasi yang lebih robust\n",
                "2. **Tabel Perbandingan**: Melihat metrik secara side-by-side\n",
                "3. **Visualisasi**: Grafik perbandingan yang mudah dipahami"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 Cross-Validation (5-Fold)\n",
                "\n",
                "**Cross-Validation** membagi data menjadi 5 bagian, melatih model pada 4 bagian dan menguji pada 1 bagian, diulang 5 kali. Ini memberikan estimasi performa yang lebih reliable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cross-Validation untuk kedua model\n",
                "print(\"=\" * 60)\n",
                "print(\"CROSS-VALIDATION (5-Fold)\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "cv_size = min(20000, len(X_scaled))\n",
                "np.random.seed(42)\n",
                "cv_indices = np.random.choice(len(X_scaled), size=cv_size, replace=False)\n",
                "\n",
                "X_cv = X_scaled.iloc[cv_indices].reset_index(drop=True)\n",
                "y_cv = y_encoded[cv_indices]\n",
                "\n",
                "cv_knn = cross_val_score(KNeighborsClassifier(n_neighbors=best_k), X_cv, y_cv, cv=5, scoring='accuracy')\n",
                "cv_rf = cross_val_score(RandomForestClassifier(\n",
                "    n_estimators=grid_search.best_params_['n_estimators'],\n",
                "    max_depth=grid_search.best_params_['max_depth'],\n",
                "    min_samples_split=grid_search.best_params_['min_samples_split'],\n",
                "    random_state=42, n_jobs=-1\n",
                "), X_cv, y_cv, cv=5, scoring='accuracy')\n",
                "\n",
                "print(f\"KNN Cross-Validation Scores: {cv_knn}\")\n",
                "print(f\"KNN Mean CV Score: {cv_knn.mean():.4f} (+/- {cv_knn.std()*2:.4f})\")\n",
                "print()\n",
                "print(f\"Random Forest Cross-Validation Scores: {cv_rf}\")\n",
                "print(f\"Random Forest Mean CV Score: {cv_rf.mean():.4f} (+/- {cv_rf.std()*2:.4f})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 Tabel Perbandingan Metrik"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tabel Perbandingan Metrik\n",
                "print(\"=\" * 60)\n",
                "print(\"PERBANDINGAN PERFORMA MODEL\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "comparison_data = {\n",
                "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'CV Mean Score'],\n",
                "    'KNN (Baseline)': [knn_accuracy, knn_precision, knn_recall, knn_f1, cv_knn.mean()],\n",
                "    'Random Forest (Advanced)': [rf_accuracy, rf_precision, rf_recall, rf_f1, cv_rf.mean()]\n",
                "}\n",
                "\n",
                "df_comparison = pd.DataFrame(comparison_data)\n",
                "df_comparison = df_comparison.set_index('Metric')\n",
                "\n",
                "df_comparison_display = df_comparison.copy()\n",
                "for col in df_comparison_display.columns:\n",
                "    df_comparison_display[col] = df_comparison_display[col].apply(lambda x: f\"{x:.4f} ({x*100:.2f}%)\")\n",
                "\n",
                "print(df_comparison_display)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.3 Visualisasi Perbandingan"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualisasi Perbandingan Metrik\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "\n",
                "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'CV Mean Score']\n",
                "x = np.arange(len(metrics))\n",
                "width = 0.35\n",
                "\n",
                "knn_scores = [knn_accuracy, knn_precision, knn_recall, knn_f1, cv_knn.mean()]\n",
                "rf_scores = [rf_accuracy, rf_precision, rf_recall, rf_f1, cv_rf.mean()]\n",
                "\n",
                "bars1 = ax.bar(x - width/2, knn_scores, width, label='KNN (Baseline)', color='#3498DB', edgecolor='white')\n",
                "bars2 = ax.bar(x + width/2, rf_scores, width, label='Random Forest (Advanced)', color='#2ECC71', edgecolor='white')\n",
                "\n",
                "ax.set_xlabel('Metrics', fontsize=12)\n",
                "ax.set_ylabel('Score', fontsize=12)\n",
                "ax.set_title('Perbandingan Performa: KNN vs Random Forest', fontsize=14, fontweight='bold')\n",
                "ax.set_xticks(x)\n",
                "ax.set_xticklabels(metrics)\n",
                "ax.legend(fontsize=11)\n",
                "ax.set_ylim(0, 1.1)\n",
                "\n",
                "for bar, score in zip(bars1, knn_scores):\n",
                "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
                "            f'{score:.3f}', ha='center', va='bottom', fontsize=9)\n",
                "for bar, score in zip(bars2, rf_scores):\n",
                "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
                "            f'{score:.3f}', ha='center', va='bottom', fontsize=9)\n",
                "\n",
                "plt.grid(axis='y', alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Visualisasi dan Analisis\n",
                "\n",
                "Analisis lanjutan untuk memahami model lebih dalam."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.1 Feature Importance\n",
                "\n",
                "Random Forest dapat menghitung **Feature Importance** yang menunjukkan fitur mana yang paling berpengaruh dalam prediksi."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature Importance dari Random Forest\n",
                "plt.figure(figsize=(10, 6))\n",
                "feature_names = ['Jenis Kelamin', 'Umur (bulan)', 'Tinggi Badan (cm)', 'Berat Badan (kg)']\n",
                "importances = rf_model.feature_importances_\n",
                "indices = np.argsort(importances)[::-1]\n",
                "\n",
                "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(feature_names)))\n",
                "plt.bar(range(len(feature_names)), importances[indices], color=colors, edgecolor='white')\n",
                "plt.xticks(range(len(feature_names)), [feature_names[i] for i in indices], rotation=45, ha='right')\n",
                "plt.xlabel('Fitur', fontsize=12)\n",
                "plt.ylabel('Importance', fontsize=12)\n",
                "plt.title('Feature Importance - Random Forest', fontsize=14, fontweight='bold')\n",
                "\n",
                "for i, (idx, imp) in enumerate(zip(indices, importances[indices])):\n",
                "    plt.text(i, imp + 0.01, f'{imp:.3f}', ha='center', fontsize=10)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nFeature Importance Ranking:\")\n",
                "for i, idx in enumerate(indices):\n",
                "    print(f\"{i+1}. {feature_names[idx]}: {importances[idx]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 Perbandingan Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perbandingan Confusion Matrix Side by Side\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
                "            xticklabels=le_stunting.classes_, yticklabels=le_stunting.classes_)\n",
                "axes[0].set_title('Confusion Matrix - KNN', fontsize=12, fontweight='bold')\n",
                "axes[0].set_xlabel('Predicted Label')\n",
                "axes[0].set_ylabel('True Label')\n",
                "\n",
                "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
                "            xticklabels=le_stunting.classes_, yticklabels=le_stunting.classes_)\n",
                "axes[1].set_title('Confusion Matrix - Random Forest', fontsize=12, fontweight='bold')\n",
                "axes[1].set_xlabel('Predicted Label')\n",
                "axes[1].set_ylabel('True Label')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Menyimpan Model untuk Deployment\n",
                "\n",
                "Model yang sudah ditraining perlu disimpan agar dapat digunakan kembali tanpa harus melatih ulang. Kita menggunakan **joblib** untuk serialisasi model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Menyimpan semua model dan preprocessor\n",
                "joblib.dump(knn_model, f'{MODEL_PATH}knn_model.joblib')\n",
                "print(f\"‚úÖ Model KNN berhasil disimpan\")\n",
                "\n",
                "joblib.dump(rf_model, f'{MODEL_PATH}rf_model.joblib')\n",
                "print(f\"‚úÖ Model Random Forest berhasil disimpan\")\n",
                "\n",
                "joblib.dump(scaler, f'{MODEL_PATH}scaler.joblib')\n",
                "print(f\"‚úÖ Scaler berhasil disimpan\")\n",
                "\n",
                "joblib.dump(le_gender, f'{MODEL_PATH}label_encoder_gender.joblib')\n",
                "print(f\"‚úÖ Label Encoder Gender berhasil disimpan\")\n",
                "\n",
                "joblib.dump(le_stunting, f'{MODEL_PATH}label_encoder_stunting.joblib')\n",
                "print(f\"‚úÖ Label Encoder Stunting berhasil disimpan\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Menyimpan informasi model\n",
                "model_info = {\n",
                "    'knn_best_k': best_k,\n",
                "    'rf_best_params': grid_search.best_params_,\n",
                "    'feature_names': feature_names,\n",
                "    'stunting_classes': list(le_stunting.classes_),\n",
                "    'gender_classes': list(le_gender.classes_),\n",
                "    'knn_metrics': {'accuracy': knn_accuracy, 'precision': knn_precision, 'recall': knn_recall, 'f1_score': knn_f1},\n",
                "    'rf_metrics': {'accuracy': rf_accuracy, 'precision': rf_precision, 'recall': rf_recall, 'f1_score': rf_f1}\n",
                "}\n",
                "\n",
                "joblib.dump(model_info, f'{MODEL_PATH}model_info.joblib')\n",
                "print(f\"‚úÖ Model info berhasil disimpan\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"SEMUA MODEL BERHASIL DISIMPAN!\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 9. Kesimpulan\n",
                "\n",
                "Berikut adalah ringkasan hasil perbandingan kedua algoritma."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 60)\n",
                "print(\"KESIMPULAN\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "print(f\"\"\"\n",
                "üìä RINGKASAN HASIL PERBANDINGAN\n",
                "{'=' * 60}\n",
                "\n",
                "1. MODEL KNN (BASELINE)\n",
                "   - Nilai K optimal: {best_k}\n",
                "   - Accuracy: {knn_accuracy:.4f} ({knn_accuracy*100:.2f}%)\n",
                "   - Precision: {knn_precision:.4f}\n",
                "   - Recall: {knn_recall:.4f}\n",
                "   - F1-Score: {knn_f1:.4f}\n",
                "\n",
                "2. MODEL RANDOM FOREST (ADVANCED)\n",
                "   - Parameters: {grid_search.best_params_}\n",
                "   - Accuracy: {rf_accuracy:.4f} ({rf_accuracy*100:.2f}%)\n",
                "   - Precision: {rf_precision:.4f}\n",
                "   - Recall: {rf_recall:.4f}\n",
                "   - F1-Score: {rf_f1:.4f}\n",
                "\"\"\")\n",
                "\n",
                "if rf_accuracy > knn_accuracy:\n",
                "    better_model = \"Random Forest\"\n",
                "    improvement = ((rf_accuracy - knn_accuracy) / knn_accuracy) * 100\n",
                "    print(f\"üèÜ MODEL TERBAIK: {better_model}\")\n",
                "    print(f\"   Peningkatan akurasi: {improvement:.2f}%\")\n",
                "else:\n",
                "    print(f\"üèÜ MODEL TERBAIK: KNN\")\n",
                "\n",
                "print(\"\"\"\n",
                "üí° ANALISIS:\n",
                "\n",
                "KELEBIHAN KNN:\n",
                "- Mudah diimplementasikan\n",
                "- Tidak memerlukan training time lama\n",
                "\n",
                "KELEBIHAN RANDOM FOREST:\n",
                "- Robust terhadap overfitting\n",
                "- Memberikan feature importance\n",
                "- Performa lebih baik untuk dataset besar\n",
                "\n",
                "üìå Model siap untuk deployment ke Streamlit!\n",
                "\"\"\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
